{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d0eeaa5",
   "metadata": {},
   "source": [
    "# State Farm Classification Problem - Suat Akbulut\n",
    "\n",
    "\n",
    "## Step 1 - Clean and prepare data\n",
    "\n",
    "### Data Cleaning\n",
    "    \n",
    "Following categorical variables had the explained data quality issues and were handled as below. \n",
    "- **x3** : Both short-hand and full version of the days of the week were present. All converted to their full version, e.g. 'Wed' -> 'Wednesday', \n",
    "- **x7** : (float) percentages were displayed as string due to '\\%' sign. Converted to float type (in terms of percentages), e.g. \n",
    "    '0.0062\\%' ==> 0.0062, \n",
    "- **x19**: (float) dollar amounts were displayed as string due to dollar sign. Converted to float type (in terms of percentages), e.g. '&#36;-908.650758' ==> -908.650758, \n",
    "- **x33** and **x99** had no variation in data, hence omitted, \n",
    "\n",
    "The same cleaning is applied to test data as well. \n",
    "\n",
    "During visual exploration, I noticed that the columns **x59**, **x79**, and **x98** were binary, so converted them to object types later in the analysis -- both in dev, val, and test sets of course. \n",
    "\n",
    "### Dev - Val split \n",
    "\n",
    "Train data is then divided into two subsets: dev and val. A GridSearchCV model is employed with a set of classification models on the dev set and their AUC score performances are comapared on the val set. \n",
    "\n",
    "### Imbalanced classes \n",
    "\n",
    "Because the data is imbalanced, I downsampled the majority class. I was not interested in mathematical certainty and just wanted a heuristic, moreover, my computer's compute power was not enough to train all the models I was considering with the upsampling, so I chose downsampling over upsampling, which could have been more accurate though. \n",
    "\n",
    "Downsampling happened only on the dev set. Therefore, val and test sets were left untouched. \n",
    "\n",
    "## Step 2 - Build models: \n",
    "\n",
    "### Preprocess\n",
    "\n",
    "- numerical columns \n",
    "    Imputed the missing variables with the mean of the train data \n",
    "    Because some of the algorithms we employ are distance based, i.e. they are sensitive to the relative dispersion fot he data points accross different columns, I scaled them using a standard scaler\n",
    "    \n",
    "- categorical columns \n",
    "    The missing variables are imputed using the most frequently observed data in that column\n",
    "    I used a One Hot Encodee to encode my categorical variables. The reason why I did not use a Label Encoder is because my categorical variables' ordinality does not matter. \n",
    "\n",
    "All the parameters needed for preprocessing such as 'mean', 'most_frequent' element, etc. are learnt in dev set and then used in val set accordingly to avoid any `data leakage`. \n",
    "\n",
    "### Train \n",
    "\n",
    "Following models have been considered, trained on the dev set using a GridSearchCV and compared on the val set based on their ROC AUC Score metric. \n",
    "\n",
    "- Logistic Regression, \n",
    "- AdaBoost Classifier,\n",
    "- KNeighbors, \n",
    "- Random Forest, \n",
    "- Decision Tree,    \n",
    "- MLP,\n",
    "- GaussianNB,\n",
    "- Quadratic Discriminant Analysis,\n",
    "- Linear SVM and \n",
    "- Non-Linear SVM \n",
    "\n",
    "## Step 3 - Generate predictions:\n",
    "\n",
    "### Submission\n",
    "\n",
    "The best performing one, based on the ROC AUC Score metric, AdaBoost Classifier (`nonglmresults.csv`) has been chosen for the submission along with the requested Logistic Regression model (`glmresults.csv`). \n",
    "\n",
    "## Step 4 - Compare the modeling approaches:\n",
    "\n",
    "### Logistic Regression vs AdaBoost \n",
    "\n",
    "Linear regressions work better when the relationships between our predictors and the target variables are linear. \n",
    "Boosting algorithms are tree based and works on information gain concepts. They perform well on dataset where we don't have linear relationship. More accurately, they don't care about linearilty.\n",
    "\n",
    "Switching from Logistic regression, a linear regression, to AdaBoost, a boosting algorithm, allows us to capture the non-linear relationships between our features and the target for this classification problem, which translates into better prediction accuracy (**0.8045** vs **0.7671**). \n",
    "\n",
    "Although AdaBoost is more resistant to overfitting than many machine learning algorithms, it is often sensitive to noisy data and outliers. (In this analysis the outliers have been removed using IsolationForest algorithm). In contrast, Logistic Regression models are not much impacted by the presence of outliers since the sigmoid function tapers the outliers. \n",
    "\n",
    "I would advocate the AdaBoost model to a business partner by emhpasising its ability to capture the non-linear relationship, while being resistant to the famous overfitting problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b09337",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --user xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4659d922",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a1bd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, IsolationForest\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import roc_auc_score, f1_score, make_scorer, accuracy_score\n",
    "from matplotlib.colors import ListedColormap\n",
    "import xgboost as xgb\n",
    "\n",
    "# importing WARNINGS class to suppress warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfabb39c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_data = pd.read_csv(\"data/exercise_40_train.csv\")\n",
    "test_data = pd.read_csv(\"data/exercise_40_test.csv\")\n",
    "\n",
    "# If train data is missing the label for some observations, drop those observations\n",
    "train_data.dropna(axis=0, subset=[\"y\"], inplace=True)\n",
    "\n",
    "# Let's have a look at the data\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2e3b6e",
   "metadata": {},
   "source": [
    "## Imbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7418c941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do we have a balanced data?\n",
    "fig = plt.figure(figsize=(4, 4))\n",
    "train_data[\"y\"].value_counts().plot(kind=\"bar\")\n",
    "plt.title(\"label balance\")\n",
    "plt.xlabel(\"label values\")\n",
    "plt.ylabel(\"amount per label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb7a655",
   "metadata": {},
   "source": [
    "We are facing an imbalanced data issue. I will downsample my train data to address this issue. The main reason why I choose downsampling over upsampling is the train set size. My computer lacks the compute power to train some of the classification models with that size of a train set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b007d8c",
   "metadata": {},
   "source": [
    "## Data Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b2982b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for data issues in categorical variables\n",
    "cat_cols = [col for col in train_data.columns if train_data[col].dtype == \"object\"]\n",
    "for col in cat_cols:\n",
    "    print(col, \"has\", train_data[col].nunique(), \"unique values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c3e967",
   "metadata": {},
   "source": [
    "I will manually consider these categorical variables to analyze if they pose any issues that needs to be addressed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587571de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do they represent, is it logical to have that many unique elements in those columns?\n",
    "train_data[cat_cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8ca0b8",
   "metadata": {},
   "source": [
    "Analyzing these columns, we observe that \n",
    "- x3 has both long and short-hand version of the days of the week, e.g. both 'Wed', and 'Wednesday' \n",
    "- x7 has percentage values as strings \n",
    "- x19 has dollar values as strings \n",
    "- x39 and x99 have no variation \n",
    "\n",
    "Following function will solve these issues.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0bec12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(X):\n",
    "    days_conversion = {\n",
    "        \"Mon\": \"Monday\",\n",
    "        \"Tue\": \"Tuesday\",\n",
    "        \"Wed\": \"Wednesday\",\n",
    "        \"Thur\": \"Thursday\",\n",
    "        \"Fri\": \"Friday\",\n",
    "        \"Sat\": \"Saturday\",\n",
    "        \"Sun\": \"Sunday\",\n",
    "    }\n",
    "\n",
    "    # Map the short-hand days to their full version, e.g. 'Wed' -> 'Wednesday'\n",
    "    X[\"x3\"] = X[\"x3\"].map(days_conversion).fillna(X[\"x3\"])\n",
    "\n",
    "    # convert (string) percentages to floats, e.g. '0.0062%' - > 0.0062\n",
    "    X[\"x7\"] = X[\"x7\"].str.replace(\"%\", \"\").astype(float)\n",
    "\n",
    "    # convert (string) dollars to floats, e.g. '$-908.650758' - >-908.650758\n",
    "    X[\"x19\"] = X[\"x19\"].str.replace(\"$\", \"\").astype(float)\n",
    "\n",
    "    # Drop the columns that do not carry information/variationå\n",
    "    X.drop([\"x39\", \"x99\"], axis=1, inplace=True)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40da9d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean both train and test data\n",
    "train_data = clean_data(train_data)\n",
    "test_data = clean_data(test_data)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73143a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Validation Split\n",
    "dev_unp, val_unp = train_test_split(train_data, test_size=0.15, random_state=42)\n",
    "\n",
    "print(\"Unprocessed dev :\", dev_unp.shape)\n",
    "print(\"Unprocessed val :\", val_unp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded07e67",
   "metadata": {},
   "source": [
    "## Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef76973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsample the minority observations in the unprocessed (have not been preprocessed yet) train data\n",
    "majority_df = dev_unp.loc[dev_unp.y == 0]\n",
    "minority_df = dev_unp.loc[dev_unp.y == 1] \n",
    "\n",
    "# employ sklearn's resampling tool\n",
    "from sklearn.utils import resample\n",
    "majority_downsampled = resample(majority_df,\n",
    "             replace=True,\n",
    "             n_samples=len(minority_df),\n",
    "             random_state=1)\n",
    "\n",
    "# combine the majority with the upsampled minority\n",
    "dev_unp_downsampled = pd.concat([majority_downsampled, minority_df]) \n",
    "\n",
    "# Display the label histogram again\n",
    "fig = plt.figure(figsize=(4,4)) \n",
    "dev_unp_downsampled[\"y\"].value_counts().plot(kind=\"bar\")\n",
    "plt.title(\"label balance - after downsampling\")\n",
    "plt.xlabel(\"label values\")\n",
    "plt.ylabel(\"amount per label\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a385563c",
   "metadata": {},
   "source": [
    "## A quick EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb9af18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate Analysis with Numerical variables\n",
    "num_cols = [\n",
    "    col\n",
    "    for col in dev_unp_downsampled.columns\n",
    "    if dev_unp_downsampled[col].dtype in [\"int64\", \"float\"]\n",
    "]\n",
    "fig = plt.figure(figsize=(16, 92))\n",
    "\n",
    "for ind, col in enumerate(num_cols):\n",
    "    sub = fig.add_subplot(25, 4, ind + 1)\n",
    "    sub.set_xlabel(col)\n",
    "    dev_unp_downsampled[col].plot(kind=\"hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1025dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical vs Target\n",
    "fig = plt.figure(figsize=(16, 92))\n",
    "\n",
    "for ind, col in enumerate(num_cols[1:-1]):\n",
    "    sub = fig.add_subplot(25, 4, ind + 1)\n",
    "    chart = sns.scatterplot(\n",
    "        data=dev_unp_downsampled, x=col, y=num_cols[ind + 2], hue=\"y\"\n",
    "    )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4b22c5",
   "metadata": {},
   "source": [
    "Above we plot $x_i$ against $x_{i+1}$ for $i=1,2, \\ldots, 99$ and mark those points corresponding to a label \"1\" with orange, while label \"0\" with blue. We conclude that a non-linear classification algorithm would serve better for our problem. \n",
    "\n",
    "A quick visual overview tells us that the columns $x_{59}$, $x_{79}$, and $x_{98}$ might in deed be categorical variables since they seem to be binary. Let's us verify this suspicion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c4c266",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_unp_downsampled[[\"x59\", \"x79\", \"x98\"]].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce636ac3",
   "metadata": {},
   "source": [
    "Our suspicions is correct. Hence, we will convert these columns to object types so that our preprocessing will later treat them as categorical variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2688349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert x59. x79, and x98 to object type for all dev_unp_downsampled, val_unp, and test_data\n",
    "def binaries_to_object_type(X):\n",
    "    X[[\"x59\", \"x79\", \"x98\"]] = X[[\"x59\", \"x79\", \"x98\"]].astype(object)\n",
    "    return X\n",
    "\n",
    "\n",
    "dev_unp_downsampled = binaries_to_object_type(dev_unp_downsampled)\n",
    "val_unp = binaries_to_object_type(val_unp)\n",
    "test_data = binaries_to_object_type(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08786b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical vs Target\n",
    "cat_cols = [\n",
    "    col\n",
    "    for col in dev_unp_downsampled.columns\n",
    "    if dev_unp_downsampled[col].dtype == \"object\"\n",
    "]\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "\n",
    "for ind, col in enumerate(cat_cols):\n",
    "    plt.xticks(rotation=90)\n",
    "    sub = fig.add_subplot(3, 4, ind + 1)\n",
    "    chart = sns.countplot(\n",
    "        data=dev_unp_downsampled,\n",
    "        x=col,\n",
    "        hue=\"y\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc80d2d",
   "metadata": {},
   "source": [
    "Even though the variation in a given value of a given categorical column is not too much, it might still helpus identify our target variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741884b7",
   "metadata": {},
   "source": [
    "## Preprocessing Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded71bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create label and unprocessed features data\n",
    "y_dev = dev_unp_downsampled[\"y\"]\n",
    "X_dev_unp = dev_unp_downsampled.drop([\"y\"], axis=1)\n",
    "\n",
    "y_val = val_unp[\"y\"]\n",
    "X_val_unp = val_unp.drop([\"y\"], axis=1)\n",
    "\n",
    "print(\"Shape of X_dev_unp and y_dev :\", X_dev_unp.shape, y_dev.shape)\n",
    "print(\"Shape of X_val_unp and y_val :\", X_val_unp.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f806190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPROCESS\n",
    "num_cols = [col for col in X_dev_unp.columns if X_dev_unp[col].dtype in [\"int64\", \"float\"]] \n",
    "cat_cols = [col for col in X_dev_unp.columns if X_dev_unp[col].dtype == \"object\" ] \n",
    "\n",
    "# Preprocessing Numerical data\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "        (\"scaler\", StandardScaler()), \n",
    "        # (\"poly\", PolynomialFeatures()) \n",
    "        ])\n",
    "\n",
    "# Preprocessing Categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")), \n",
    "        # (\"interaction\", PolynomialFeatures(interaction_only=True))    \n",
    "        ])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "                (\"num\", numerical_transformer, num_cols),\n",
    "                (\"cat\", categorical_transformer, cat_cols)\n",
    "                ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f17508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Employ the preprocessing to create our X_train and y_train\n",
    "X_dev = preprocessor.fit_transform(X_dev_unp)\n",
    "X_val = preprocessor.transform(X_val_unp)\n",
    "\n",
    "# preprocess the test data as well\n",
    "X_test = preprocessor.transform(test_data)\n",
    "\n",
    "print(\"X_dev  :\", X_dev.shape)\n",
    "print(\"X_val  :\", X_val.shape)\n",
    "print(\"X_test :\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7842b9",
   "metadata": {},
   "source": [
    "Some of the classifiers are distance-dependent learning models, i.e., not only the ordinality of the values matters but also the cardinality of them. Therefore, I scaled my numerical variables using StandardScaler. \n",
    "However, some classifiers are not distance-dependent, e.g., Random Forest classification, hence, this step will only increase the run-time for them. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f0b295",
   "metadata": {},
   "source": [
    "## Outliers in train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8444ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify outliers in the training dataset and elimiate them\n",
    "iso = IsolationForest(contamination=0.1)\n",
    "yhat = iso.fit_predict(X_dev)\n",
    "# select all rows that are not outliers\n",
    "mask = yhat != -1\n",
    "X_dev, y_dev = X_dev[mask, :], y_dev[mask]\n",
    "\n",
    "print(\"Shape of X_dev after removing outliers:\", X_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5651c2",
   "metadata": {},
   "source": [
    "## Train multiple models using GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b66489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, grid_parameter):\n",
    "    # run grid search to find best params\n",
    "    scorer = make_scorer(f1_score)\n",
    "    clf = GridSearchCV(classifier, grid_parameter, cv=5, scoring=scorer, n_jobs=-1)\n",
    "\n",
    "    # fit Logistic Regression\n",
    "    classifier_name = str(classifier).replace(\"()\", \"\")\n",
    "    title = f\"{classifier_name} model\"\n",
    "    print(title)\n",
    "    print(len(title) * \"=\")\n",
    "    start = time.time()\n",
    "    clf.fit(X_dev, y_dev)\n",
    "    train_time = round((time.time() - start) / 60, 2)\n",
    "    print(f\"Fitting took {train_time} mins.\")\n",
    "\n",
    "    # Generate predicted probabilites\n",
    "    start = time.time()\n",
    "    clf_probs = clf.predict_proba(X_val)\n",
    "    predict_time = round((time.time() - start) / 60, 2)\n",
    "    print(f\"Prediction took {predict_time} mins.\")\n",
    "\n",
    "    # Calculate roc_auc_score and f1_score\n",
    "    auc_score = roc_auc_score(y_val, clf_probs[:, 1])\n",
    "    y_pred = clf.predict(X_val)\n",
    "    f_score = f1_score(y_val, y_pred)\n",
    "\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "\n",
    "    print(\"AUC Score:\", auc_score)\n",
    "    print(\n",
    "        \"F1 Score :\",\n",
    "        f_score,\n",
    "    )\n",
    "    print(\"Accuracy :\", accuracy, \"\\n\")\n",
    "    return [\n",
    "        classifier_name,\n",
    "        clf,\n",
    "        train_time,\n",
    "        predict_time,\n",
    "        f_score,\n",
    "        auc_score,\n",
    "        accuracy,\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ffa6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    classifier_class,\n",
    "    trained_model,\n",
    "    train_time,\n",
    "    predict_time,\n",
    "    f_score,\n",
    "    auc_score,\n",
    "    accuracy,\n",
    "] = train_model(classifier, grid_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b11178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider the following classification methods with the below parameter grids for optimization. \n",
    "classifiers  = {\n",
    "    \"log\" : LogisticRegression(), \n",
    "    \"xgb\" : xgb.XGBClassifier(),\n",
    "    \"knn\" : KNeighborsClassifier(),\n",
    "    \"rf\"  : RandomForestClassifier(),\n",
    "    \"dt\"  : DecisionTreeClassifier(),    \n",
    "    \"nn\"  : MLPClassifier(),\n",
    "    \"ada\" : AdaBoostClassifier(),\n",
    "    \"gnb\" : GaussianNB(),\n",
    "    \"quad\": QuadraticDiscriminantAnalysis(),\n",
    "    \"svm_lin\" : SVC(kernel=\"linear\", probability=True),\n",
    "    \"svm\" : SVC(kernel=\"rbf\", probability=True),\n",
    "}\n",
    "\n",
    "grid_parameters = [\n",
    "    [{\"max_iter\": [250, 370, 540], \n",
    "      \"penalty\": [\"l2\", \"none\"] }],\n",
    "    [{\"learning_rate\": [0.1, 0.01, 0.05], }],\n",
    "    [{\"n_neighbors\": [3,5,7] }],\n",
    "    [{\"max_depth\" : [25, None], \n",
    "      \"n_estimators\": [51, 151, 251] }]  , \n",
    "    [{\"max_depth\" : [20, 50, 100, None], \n",
    "      \"criterion\" : [\"gini\", \"entropy\", \"log_loss\"] }] ,      \n",
    "    [{\"hidden_layer_sizes\": [[10, 10, 5], [10, 10], [15, 15]], \n",
    "      \"alpha\" : [0.0003, 0.03] }],\n",
    "    [{\"n_estimators\": [51, 151, 251], \n",
    "      \"learning_rate\" : [0.03, 0.3, 1, 10] }],    \n",
    "    [{\"var_smoothing\": [1e-9] }],\n",
    "    [{\"reg_param\": [0.0] }], \n",
    "    [{\"gamma\": [\"auto\", 0.025] }],\n",
    "    [{\"gamma\": [\"auto\", 0.025] }],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d737b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and compare all above models and save the results in df\n",
    "df = pd.DataFrame(columns = [\"classifier_class\", \"trained_model\", \"train_time\", \"predict_time\", \"F1_Score\", \"AUC\", \"Accuracy\"])\n",
    "\n",
    "for [test, classifier] , grid_parameter in zip(classifiers.items(), grid_parameters):\n",
    "    [classifier_class, trained_model, train_time, predict_time, f_score, auc_score, accuracy] = train_model(classifier, grid_parameter)\n",
    "    df.loc[len(df)] = [classifier_class, trained_model, train_time, predict_time, f_score, auc_score, accuracy]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56578703",
   "metadata": {},
   "source": [
    "## Trained models and their AUC scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e9c824",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set the pandas display options to see the full dataframe\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", None)\n",
    "pd.set_option(\"display.max_colwidth\", -1)\n",
    "\n",
    "# Sort the models based on their AUC score \n",
    "df.sort_values(by=\"AUC\", ascending=False, inplace = True)\n",
    "df.reset_index(drop=True, inplace = True)\n",
    "display( df )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1beb9102",
   "metadata": {},
   "source": [
    "## Prepare Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8738e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission using Logistic Regression\n",
    "log_model = df.loc[df.classifier_class == \"LogisticRegression\"].trained_model.values[0]\n",
    "\n",
    "# Predict probabilities\n",
    "clf_log_probs = log_model.predict_proba(X_test)\n",
    "\n",
    "# saves probabilities as csv\n",
    "np.savetxt(\"submission/glmresults.csv\", np.around(clf_log_probs[:,1], decimals=4), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752265fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission using the best performing classifier, AdaBoosClassifier \n",
    "# if the best performing one is Logistic Regression, then obtain the second best\n",
    "ind = 0\n",
    "if df.iloc[0].classifier_class == \"LogisticRegression\":\n",
    "    ind = 1\n",
    "best_model = df.iloc[ind].trained_model\n",
    "\n",
    "# Predict probabilities\n",
    "clf_best_probs = best_model.predict_proba(X_test)\n",
    "\n",
    "# saves probabilities as csv\n",
    "np.savetxt(\"submission/nonglmresults.csv\", np.around(clf_best_probs[:,1], decimals=4), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312c1e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save this notebook as a pdf\n",
    "!jupyter nbconvert --to webpdf --allow-chromium-download Suat_Akbulut_Classsification.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3861dfe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a462f61f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e2e52ba",
   "metadata": {},
   "source": [
    "## Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137ab33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d619b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(64, activation=\"relu\", input_shape=(X_dev.shape[-1],)),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(64, activation=\"relu\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dropout(0.3),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-2),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=keras.metrics.AUC(name=\"auc\"),\n",
    ")\n",
    "\n",
    "# callbacks = [keras.callbacks.ModelCheckpoint(\"fraud_model_at_epoch_{epoch}.h5\")]\n",
    "# class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "model.fit(\n",
    "    X_dev,\n",
    "    y_dev,\n",
    "    batch_size=2048,\n",
    "    epochs=30,\n",
    "    verbose=2,\n",
    "    # callbacks=callbacks,\n",
    "    validation_data=(X_val, y_val),\n",
    "    # class_weight=class_weight,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa665ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = model.predict(X_val)\n",
    "y_pred = 1 * (y_pred_prob > 0.5)\n",
    "\n",
    "\n",
    "auc_score = roc_auc_score(y_val, y_pred_prob)\n",
    "\n",
    "f_score = f1_score(y_val, y_pred)\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "\n",
    "print(\"AUC Score:\", auc_score)\n",
    "print(\"F1 Score :\", f_score)\n",
    "print(\"Accuracy :\", accuracy, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70000c94",
   "metadata": {},
   "source": [
    "## Alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95af1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "    #    keras.metrics.TruePositives(name=\"tp\"),\n",
    "    #    keras.metrics.FalsePositives(name=\"fp\"),\n",
    "    #    keras.metrics.TrueNegatives(name=\"tn\"),\n",
    "    #    keras.metrics.FalseNegatives(name=\"fn\"),\n",
    "    keras.metrics.BinaryAccuracy(name=\"accuracy\"),\n",
    "    # keras.metrics.F1Score(name=\"f1score\"),\n",
    "    keras.metrics.AUC(name=\"auc\"),\n",
    "]\n",
    "\n",
    "\n",
    "def make_model(metrics=METRICS, output_bias=None):\n",
    "    if output_bias is not None:\n",
    "        output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.layers.Dense(32, activation=\"relu\", input_shape=(X_dev.shape[-1],)),\n",
    "            keras.layers.Dropout(0.3),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Dense(32, activation=\"relu\"),\n",
    "            keras.layers.Dropout(0.3),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Dense(1, activation=\"sigmoid\", bias_initializer=output_bias),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        loss=keras.losses.BinaryCrossentropy(),\n",
    "        metrics=metrics,\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 2048\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_auc\", verbose=1, patience=10, mode=\"max\", restore_best_weights=True\n",
    ")\n",
    "\n",
    "model = make_model()\n",
    "print( model.summary() )\n",
    "\n",
    "history = model.fit(\n",
    "    X_dev,\n",
    "    y_dev,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=2,\n",
    "    callbacks=[early_stopping],\n",
    "    validation_data=(X_val, y_val),\n",
    "    # class_weight=class_weight,\n",
    ")\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams[\"figure.figsize\"] = (12, 10)\n",
    "colors = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "\n",
    "\n",
    "def plot_metrics(history):\n",
    "    metrics = [\"loss\", \"auc\", \"accuracy\"]\n",
    "    for n, metric in enumerate(metrics):\n",
    "        name = metric.replace(\"_\", \" \").capitalize()\n",
    "        plt.subplot(2, 2, n + 1)\n",
    "        plt.plot(history.epoch, history.history[metric], color=colors[0], label=\"Train\")\n",
    "        plt.plot(\n",
    "            history.epoch,\n",
    "            history.history[\"val_\" + metric],\n",
    "            color=colors[0],\n",
    "            linestyle=\"--\",\n",
    "            label=\"Val\",\n",
    "        )\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(name)\n",
    "        if metric == \"loss\":\n",
    "            plt.ylim([0, plt.ylim()[1]])\n",
    "        elif metric == \"auc\":\n",
    "            plt.ylim([0.7, 0.9])\n",
    "        else:\n",
    "            plt.ylim([0, 1])\n",
    "\n",
    "        plt.legend()\n",
    "\n",
    "\n",
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d888dbd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6c77bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873041af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75991324",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
